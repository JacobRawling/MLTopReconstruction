{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parton_t_lep_Pt</th>\n",
       "      <th>parton_t_lep_Eta</th>\n",
       "      <th>parton_t_lep_Phi</th>\n",
       "      <th>parton_t_lep_M</th>\n",
       "      <th>parton_t_had_Pt</th>\n",
       "      <th>parton_t_had_Eta</th>\n",
       "      <th>parton_t_had_Phi</th>\n",
       "      <th>parton_t_had_M</th>\n",
       "      <th>parton_W_had_Pt</th>\n",
       "      <th>parton_W_had_Eta</th>\n",
       "      <th>...</th>\n",
       "      <th>b_lep_Phi</th>\n",
       "      <th>b_lep_E</th>\n",
       "      <th>b_had_Pt</th>\n",
       "      <th>b_had_Eta</th>\n",
       "      <th>b_had_Phi</th>\n",
       "      <th>b_had_E</th>\n",
       "      <th>W_lep_Pt</th>\n",
       "      <th>W_lep_Eta</th>\n",
       "      <th>W_lep_Phi</th>\n",
       "      <th>W_lep_E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26210.712891</td>\n",
       "      <td>-2.813584</td>\n",
       "      <td>1.222510</td>\n",
       "      <td>172521.125000</td>\n",
       "      <td>72533.125000</td>\n",
       "      <td>-3.675916</td>\n",
       "      <td>1.456350</td>\n",
       "      <td>172723.531250</td>\n",
       "      <td>114015.984375</td>\n",
       "      <td>-3.021512</td>\n",
       "      <td>...</td>\n",
       "      <td>2.412543</td>\n",
       "      <td>130343.023438</td>\n",
       "      <td>201853.781250</td>\n",
       "      <td>0.592402</td>\n",
       "      <td>-0.441704</td>\n",
       "      <td>238950.625000</td>\n",
       "      <td>135686.473118</td>\n",
       "      <td>2.138249</td>\n",
       "      <td>2.359626</td>\n",
       "      <td>589988.274388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92752.843750</td>\n",
       "      <td>-1.496029</td>\n",
       "      <td>2.613532</td>\n",
       "      <td>176464.171875</td>\n",
       "      <td>96631.039062</td>\n",
       "      <td>-2.584467</td>\n",
       "      <td>-0.316401</td>\n",
       "      <td>170910.125000</td>\n",
       "      <td>75805.507812</td>\n",
       "      <td>-2.085379</td>\n",
       "      <td>...</td>\n",
       "      <td>2.573960</td>\n",
       "      <td>92072.093750</td>\n",
       "      <td>34999.722656</td>\n",
       "      <td>-0.036871</td>\n",
       "      <td>-0.790957</td>\n",
       "      <td>35248.691406</td>\n",
       "      <td>36329.159212</td>\n",
       "      <td>1.782928</td>\n",
       "      <td>-1.464808</td>\n",
       "      <td>137125.985111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139194.140625</td>\n",
       "      <td>-0.391737</td>\n",
       "      <td>-3.099086</td>\n",
       "      <td>170435.546875</td>\n",
       "      <td>135427.390625</td>\n",
       "      <td>0.811365</td>\n",
       "      <td>0.089600</td>\n",
       "      <td>173165.109375</td>\n",
       "      <td>149896.234375</td>\n",
       "      <td>0.775999</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.870163</td>\n",
       "      <td>104799.687500</td>\n",
       "      <td>41540.578125</td>\n",
       "      <td>2.103381</td>\n",
       "      <td>1.266825</td>\n",
       "      <td>172784.843750</td>\n",
       "      <td>82647.169437</td>\n",
       "      <td>-0.580798</td>\n",
       "      <td>-0.677408</td>\n",
       "      <td>125975.005508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35275.816406</td>\n",
       "      <td>1.068851</td>\n",
       "      <td>1.896412</td>\n",
       "      <td>172743.640625</td>\n",
       "      <td>44878.582031</td>\n",
       "      <td>1.920528</td>\n",
       "      <td>-2.050357</td>\n",
       "      <td>172766.781250</td>\n",
       "      <td>65037.789062</td>\n",
       "      <td>0.261693</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.561372</td>\n",
       "      <td>270595.156250</td>\n",
       "      <td>27744.072266</td>\n",
       "      <td>0.817976</td>\n",
       "      <td>2.255633</td>\n",
       "      <td>37834.363281</td>\n",
       "      <td>102641.485570</td>\n",
       "      <td>2.250263</td>\n",
       "      <td>-1.864985</td>\n",
       "      <td>498973.213324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38095.621094</td>\n",
       "      <td>0.194375</td>\n",
       "      <td>-0.120800</td>\n",
       "      <td>171511.437500</td>\n",
       "      <td>83400.218750</td>\n",
       "      <td>-0.696042</td>\n",
       "      <td>-2.875081</td>\n",
       "      <td>173112.609375</td>\n",
       "      <td>117186.085937</td>\n",
       "      <td>-0.156181</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.325078</td>\n",
       "      <td>216230.812500</td>\n",
       "      <td>59974.976562</td>\n",
       "      <td>-0.334010</td>\n",
       "      <td>1.645467</td>\n",
       "      <td>63570.820312</td>\n",
       "      <td>110140.405600</td>\n",
       "      <td>-1.242552</td>\n",
       "      <td>-0.792195</td>\n",
       "      <td>221770.231981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   parton_t_lep_Pt   parton_t_lep_Eta   parton_t_lep_Phi   parton_t_lep_M  \\\n",
       "0     26210.712891          -2.813584           1.222510    172521.125000   \n",
       "1     92752.843750          -1.496029           2.613532    176464.171875   \n",
       "2    139194.140625          -0.391737          -3.099086    170435.546875   \n",
       "3     35275.816406           1.068851           1.896412    172743.640625   \n",
       "4     38095.621094           0.194375          -0.120800    171511.437500   \n",
       "\n",
       "    parton_t_had_Pt   parton_t_had_Eta   parton_t_had_Phi   parton_t_had_M  \\\n",
       "0      72533.125000          -3.675916           1.456350    172723.531250   \n",
       "1      96631.039062          -2.584467          -0.316401    170910.125000   \n",
       "2     135427.390625           0.811365           0.089600    173165.109375   \n",
       "3      44878.582031           1.920528          -2.050357    172766.781250   \n",
       "4      83400.218750          -0.696042          -2.875081    173112.609375   \n",
       "\n",
       "    parton_W_had_Pt   parton_W_had_Eta      ...         b_lep_Phi  \\\n",
       "0     114015.984375          -3.021512      ...          2.412543   \n",
       "1      75805.507812          -2.085379      ...          2.573960   \n",
       "2     149896.234375           0.775999      ...         -2.870163   \n",
       "3      65037.789062           0.261693      ...         -1.561372   \n",
       "4     117186.085937          -0.156181      ...         -2.325078   \n",
       "\n",
       "         b_lep_E       b_had_Pt   b_had_Eta   b_had_Phi        b_had_E  \\\n",
       "0  130343.023438  201853.781250    0.592402   -0.441704  238950.625000   \n",
       "1   92072.093750   34999.722656   -0.036871   -0.790957   35248.691406   \n",
       "2  104799.687500   41540.578125    2.103381    1.266825  172784.843750   \n",
       "3  270595.156250   27744.072266    0.817976    2.255633   37834.363281   \n",
       "4  216230.812500   59974.976562   -0.334010    1.645467   63570.820312   \n",
       "\n",
       "        W_lep_Pt   W_lep_Eta   W_lep_Phi        W_lep_E  \n",
       "0  135686.473118    2.138249    2.359626  589988.274388  \n",
       "1   36329.159212    1.782928   -1.464808  137125.985111  \n",
       "2   82647.169437   -0.580798   -0.677408  125975.005508  \n",
       "3  102641.485570    2.250263   -1.864985  498973.213324  \n",
       "4  110140.405600   -1.242552   -0.792195  221770.231981  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "in_datafile = \"in/ttj.csv\"\n",
    "df = pd.read_csv(in_datafile)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train dataframe of size:  722\n",
      "Created test dataframe of size:   390\n"
     ]
    }
   ],
   "source": [
    "fraction_train = 0.65 \n",
    "max_size = len(df)\n",
    "train_df = df[:int(max_size*fraction_train)]\n",
    "test_df  = df[int(max_size*fraction_train):max_size]\n",
    "print \"Created train dataframe of size: \", len(train_df)\n",
    "print \"Created test dataframe of size:  \", len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input X and Y vectors\n",
    "\n",
    "Set-up the input and output vectors. \n",
    "\n",
    "The output vector is going to be the jet indices:\n",
    "    ( \n",
    "    \n",
    "        is_fisrt_bjet_leptonic\n",
    "        is_second_bjet_hadronic,\n",
    "        is_in_W\n",
    "        is_in_W,\n",
    "        is_in_W,\n",
    "    )\n",
    "Then some spectator variables needed for the custom loss function that minimizes differences in four momenta: \n",
    "    (\n",
    "    \n",
    "        parton_top_had_p4,\n",
    "        parton_top_lep_p4,\n",
    "        parton_w_had_p4,\n",
    "        reco_w_lep_p4,\n",
    "        reco_bjet_1\n",
    "        reco_bjet_2\n",
    "        reco_jet_1\n",
    "        reco_jet_2\n",
    "        reco_jet_3     \n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(722, 20)\n",
      "(722, 21)\n",
      "['parton_t_lep_Pt', ' parton_t_lep_Eta', ' parton_t_lep_Phi', ' parton_t_lep_M', ' parton_t_had_Pt', ' parton_t_had_Eta', ' parton_t_had_Phi', ' parton_t_had_M', ' parton_W_had_Pt', ' parton_W_had_Eta', ' parton_W_had_Phi', ' parton_W_had_M', ' W_lep_Pt', ' W_lep_Eta', ' W_lep_Phi', ' W_lep_E']\n",
      "[' jet1_Pt', ' jet1_Eta', ' jet1_Phi', ' jet1_E', ' jet2_Pt', ' jet2_Eta', ' jet2_Phi', ' jet2_E', ' jet3_Pt', ' jet3_Eta', ' jet3_Phi', ' jet3_E', ' b_lep_Pt', ' b_lep_Eta', ' b_lep_Phi', ' b_lep_E', ' b_had_Pt', ' b_had_Eta', ' b_had_Phi', ' b_had_E']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_variables = list(df.columns.values)\n",
    "reco_variables = all_variables[12:24]+all_variables[32:40]\n",
    "# parton_variables = all_variables[0:12]+all_variables[24:32]+all_variables[40:44]\n",
    "parton_variables = all_variables[0:12]+all_variables[40:44]\n",
    "\n",
    "X_train = np.array(train_df[reco_variables])\n",
    "Y_train = np.array(train_df[parton_variables])\n",
    "for i in xrange(5):\n",
    "    Y_train =  np.insert(Y_train, 0,0, axis=1)\n",
    "\n",
    "print X_train.shape\n",
    "print Y_train.shape\n",
    "\n",
    "print parton_variables\n",
    "print reco_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n",
      "[5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "b = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "print b[:4]\n",
    "print b[4:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ROOT as r \n",
    "from keras import backend as K\n",
    "\n",
    "def transform_to_jet_assignment(y_pred):\n",
    "    \"\"\"\n",
    "        Convert a 3-vector that sums to unity into a vector of 3 predictions\n",
    "        where:\n",
    "            first element represents  if jet_1 is in the  hadronic W\n",
    "            second element represents if jet_2 is in the  hadronic W\n",
    "            third element represents  if bjet_1 is in the hadronic top\n",
    "            \n",
    "            The jet_3 is therefore in the hadronic_W when (2 - [0]-[1] ) == 1\n",
    "            The bjet_2 is therefore in the hadronic_W when (1 - [2] ) == 1\n",
    "    \"\"\"\n",
    "    return y_pred\n",
    "\n",
    "def mass_diff_loss(y_true,y_pred):\n",
    "    \"\"\"\n",
    "        user defined evaluation function, return a pair (metric_name, result)        \n",
    "        See the following links for details \n",
    "            https://github.com/keras-team/keras/issues/4781\n",
    "            https://stackoverflow.com/questions/45961428/make-a-custom-loss-function-in-keras\n",
    "        \n",
    "        \n",
    "        Intended to be used with 16 so-called spectator variables that correspond to\n",
    "        the truth level leptonic and hadronic top, truth level hadronic W, and reconstucted\n",
    "        leptonic W boson four momemtum\n",
    "        \n",
    "        A further 20 spectator variables are passed that correspond to the reconstruction level\n",
    "        jets, 3 light jets and 2 b-jets. \n",
    "        \n",
    "        The only part of y_pred that effects this loss function is the last 3 elements. These \n",
    "        correspond to jet assignment. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Note everything is done by tensor algebra - so this actually working things out for\n",
    "    # every event in a batch all in one go using a highly optimized tensorflow backend\n",
    "        \n",
    "    # Transform predictions into booleans that represent\n",
    "    # if a jet is a decay product of the hadronic top quark \n",
    "    assignment = transform_to_jet_assignment(y_pred[-3:]) \n",
    "    \n",
    "    # Get the four vectors for each of the needed physics objects\n",
    "    # we're in a basis such that each four vector = (px,py,pz,E)\n",
    "    jet_1       = y_pred[0:4]\n",
    "    jet_2       = y_pred[4:8]\n",
    "    jet_3       = y_pred[8:12]\n",
    "    bjet_1      = y_pred[12:16]\n",
    "    bjet_2      = y_pred[16:20]\n",
    "    w_lep_truth  = y_pred[20:24]\n",
    "    t_lep_truth  = y_pred[24:28]\n",
    "    t_had_truth  = y_pred[28:32]\n",
    "    w_had_truth  = y_pred[32:36]\n",
    "    \n",
    "    # calculated the masses for all of the predictions and truth level objects\n",
    "    top_hadronic_px  = assignment[0]*jet_1[0] + assignment[1]*jet_2[0] + (2-assignment[1])*jet_3[0] + assignment[2]*bjet_1[0]+ (1-assignment[2])*bjet_2[0]\n",
    "    top_hadronic_py  = assignment[0]*jet_1[1] + assignment[1]*jet_2[1] + (2-assignment[1])*jet_3[1] + assignment[2]*bjet_1[1]+ (1-assignment[2])*bjet_2[1]\n",
    "    top_hadronic_pz  = assignment[0]*jet_1[2] + assignment[1]*jet_2[2] + (2-assignment[1])*jet_3[2] + assignment[2]*bjet_1[2]+ (1-assignment[2])*bjet_2[2]\n",
    "    top_hadronic_e   = assignment[0]*jet_1[3] + assignment[1]*jet_2[3] + (2-assignment[1])*jet_3[3] + assignment[2]*bjet_1[3]+ (1-assignment[2])*bjet_2[3]\n",
    "    top_hadronic_m    = K.square(top_hadronic_e) - (K.square(top_hadronic_px)+K.square(top_hadronic_py)+K.square(top_hadronic_pz))\n",
    "    \n",
    "    w_hadronic_px  = assignment[0]*jet_1[0] + assignment[1]*jet_2[0]  + (2-assignment[1])*jet_3[0]\n",
    "    w_hadronic_py  = assignment[0]*jet_1[1] + assignment[1]*jet_2[1]  + (2-assignment[1])*jet_3[1]\n",
    "    w_hadronic_pz  = assignment[0]*jet_1[2] + assignment[1]*jet_2[2]  + (2-assignment[1])*jet_3[2]\n",
    "    w_hadronic_e   = assignment[0]*jet_1[3] + assignment[1]*jet_2[3]  + (2-assignment[1])*jet_3[3]\n",
    "    w_hadronic_m    = K.square(w_hadronic_e) - (K.square(w_hadronic_px)+K.square(w_hadronic_py)+K.square(w_hadronic_pz))\n",
    "    \n",
    "    t_lep_truth_m   = K.square(t_lep_truth[4]) - K.square(t_lep_truth[0]) - K.square(t_lep_truth[1]) - K.square(t_lep_truth[2])\n",
    "    t_had_truth_m   = K.square(t_had_truth[4]) - K.square(t_had_truth[0]) - K.square(t_had_truth[1]) - K.square(t_had_truth[2])\n",
    "    w_had_truth_m   = K.square(w_had_truth[4]) - K.square(w_had_truth[0]) - K.square(w_had_truth[1]) - K.square(w_had_truth[2])\n",
    "    w_lep_truth_m   = K.square(w_lep_truth[4]) - K.square(w_lep_truth[0]) - K.square(w_lep_truth[1]) - K.square(w_lep_truth[2])\n",
    "    \n",
    "    top_lep_pz = w_lep_truth[0] + (1-assignment[2])*bjet_1[0]+ (assignment[2])*bjet_2[0]\n",
    "    top_lep_py = w_lep_truth[1] + (1-assignment[2])*bjet_1[1]+ (assignment[2])*bjet_2[1]\n",
    "    top_lep_px = w_lep_truth[2] + (1-assignment[2])*bjet_1[2]+ (assignment[2])*bjet_2[2]\n",
    "    top_lep_e  = w_lep_truth[3] + (1-assignment[2])*bjet_1[3]+ (assignment[2])*bjet_2[3]\n",
    "    top_lep_m   = K.square(top_lep_e) - (K.square(top_lep_px)+K.square(top_lep_py)+K.square(top_lep_pz))\n",
    "    \n",
    "    # Return the loss as the differences in mass for each of the reconstructed objects \n",
    "    return K.square(top_lep_m-t_lep_truth_m) + K.square(top_hadronic_m-t_had_truth_m)+K.square(w_hadronic_m-w_had_truth_m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "RecoJetInput (InputLayer)        (None, 32)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "JetAssignment2ndLayer (Dense)    (None, 3)             99          RecoJetInput[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "TruthLevelInput (InputLayer)     (None, 36)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)     (None, 39)            0           JetAssignment2ndLayer[0][0]      \n",
      "                                                                   TruthLevelInput[0][0]            \n",
      "====================================================================================================\n",
      "Total params: 99\n",
      "Trainable params: 99\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# Construct the jet assignment part of the network, a simple MLP\n",
    "jet_assignment_input  = Input(shape=(32,), dtype='float32', name='RecoJetInput')\n",
    "jet_assignment_output = Dense(32, activation='relu', name='JetAssignmentLayer')(jet_assignment_input)\n",
    "jet_assignment_output = Dense(3,  activation='relu', name='JetAssignment2ndLayer')(jet_assignment_input)\n",
    "\n",
    "# Potenttially might want to add additional W mass reconstruction part of the network here??\n",
    "# auxiliary_output = Dense(3, activation='sigmoid', name='aux_output')(jet_assignment_input)\n",
    "\n",
    "# Merge in truth level information required for the \n",
    "auxiliary_input = Input(shape=(36,), name='TruthLevelInput')\n",
    "x = concatenate([jet_assignment_output, auxiliary_input])\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "# output = Dense(3, activation='sigmoid', name='Output')(x)\n",
    "\n",
    "model = Model(inputs=[auxiliary_input,jet_assignment_input], outputs=[x])\n",
    "model.compile(optimizer='rmsprop', loss=mass_diff_loss)\n",
    "model.summary()\n",
    "plot_model(model, to_file='model.png',show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parton_t_lep_Px</th>\n",
       "      <th>parton_t_lep_Py</th>\n",
       "      <th>parton_t_lep_Pz</th>\n",
       "      <th>parton_t_lep_E</th>\n",
       "      <th>parton_t_had_Px</th>\n",
       "      <th>parton_t_had_Py</th>\n",
       "      <th>parton_t_had_Pz</th>\n",
       "      <th>parton_t_had_E</th>\n",
       "      <th>parton_W_had_Px</th>\n",
       "      <th>parton_W_had_Py</th>\n",
       "      <th>...</th>\n",
       "      <th>b_lep_Pz</th>\n",
       "      <th>b_lep_E</th>\n",
       "      <th>b_had_Px</th>\n",
       "      <th>b_had_Py</th>\n",
       "      <th>b_had_Pz</th>\n",
       "      <th>b_had_E</th>\n",
       "      <th>W_lep_Px</th>\n",
       "      <th>W_lep_Py</th>\n",
       "      <th>W_lep_Pz</th>\n",
       "      <th>W_lep_E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8945.401616</td>\n",
       "      <td>24636.989673</td>\n",
       "      <td>-217674.294110</td>\n",
       "      <td>278985.014576</td>\n",
       "      <td>8283.042475</td>\n",
       "      <td>72058.624950</td>\n",
       "      <td>-1.431059e+06</td>\n",
       "      <td>1.443269e+06</td>\n",
       "      <td>-5097.826232</td>\n",
       "      <td>113901.961619</td>\n",
       "      <td>...</td>\n",
       "      <td>98667.859894</td>\n",
       "      <td>130343.023438</td>\n",
       "      <td>182480.734593</td>\n",
       "      <td>-86288.646457</td>\n",
       "      <td>126696.390732</td>\n",
       "      <td>238950.625000</td>\n",
       "      <td>-96273.537082</td>\n",
       "      <td>95614.983370</td>\n",
       "      <td>567624.355242</td>\n",
       "      <td>589988.274388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-80118.597231</td>\n",
       "      <td>46734.359967</td>\n",
       "      <td>-196631.866458</td>\n",
       "      <td>280012.115606</td>\n",
       "      <td>91834.412337</td>\n",
       "      <td>-30066.566498</td>\n",
       "      <td>-6.368368e+05</td>\n",
       "      <td>6.664149e+05</td>\n",
       "      <td>59056.754405</td>\n",
       "      <td>47526.569137</td>\n",
       "      <td>...</td>\n",
       "      <td>-38662.132083</td>\n",
       "      <td>92072.093750</td>\n",
       "      <td>24610.596015</td>\n",
       "      <td>-24885.721805</td>\n",
       "      <td>-1290.778056</td>\n",
       "      <td>35248.691406</td>\n",
       "      <td>3843.260993</td>\n",
       "      <td>-36125.297978</td>\n",
       "      <td>104974.895963</td>\n",
       "      <td>137125.985111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-139068.409348</td>\n",
       "      <td>-5914.922283</td>\n",
       "      <td>-55932.889577</td>\n",
       "      <td>227050.154282</td>\n",
       "      <td>134884.134442</td>\n",
       "      <td>12118.102464</td>\n",
       "      <td>1.223401e+05</td>\n",
       "      <td>2.515827e+05</td>\n",
       "      <td>141515.876349</td>\n",
       "      <td>49417.990863</td>\n",
       "      <td>...</td>\n",
       "      <td>92647.314813</td>\n",
       "      <td>104799.687500</td>\n",
       "      <td>12433.568687</td>\n",
       "      <td>39636.170358</td>\n",
       "      <td>167653.218337</td>\n",
       "      <td>172784.843750</td>\n",
       "      <td>64398.679896</td>\n",
       "      <td>-51801.203111</td>\n",
       "      <td>-50745.918019</td>\n",
       "      <td>125975.005508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-11284.473842</td>\n",
       "      <td>33422.206289</td>\n",
       "      <td>45305.217967</td>\n",
       "      <td>182036.566037</td>\n",
       "      <td>-20706.489425</td>\n",
       "      <td>-39816.182901</td>\n",
       "      <td>1.498502e+05</td>\n",
       "      <td>2.330612e+05</td>\n",
       "      <td>-24395.980797</td>\n",
       "      <td>-60288.888919</td>\n",
       "      <td>...</td>\n",
       "      <td>131924.418297</td>\n",
       "      <td>270595.156250</td>\n",
       "      <td>-17549.408595</td>\n",
       "      <td>21488.410919</td>\n",
       "      <td>25310.706765</td>\n",
       "      <td>37834.363281</td>\n",
       "      <td>-29762.306190</td>\n",
       "      <td>-98231.765180</td>\n",
       "      <td>481637.824359</td>\n",
       "      <td>498973.213324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37818.001459</td>\n",
       "      <td>-4590.763785</td>\n",
       "      <td>7451.532982</td>\n",
       "      <td>175849.295943</td>\n",
       "      <td>-80455.810381</td>\n",
       "      <td>-21964.950795</td>\n",
       "      <td>-6.285217e+04</td>\n",
       "      <td>2.021731e+05</td>\n",
       "      <td>-116825.975467</td>\n",
       "      <td>-9179.879824</td>\n",
       "      <td>...</td>\n",
       "      <td>-212533.902475</td>\n",
       "      <td>216230.812500</td>\n",
       "      <td>-4474.206790</td>\n",
       "      <td>59807.853057</td>\n",
       "      <td>-20406.806245</td>\n",
       "      <td>63570.820312</td>\n",
       "      <td>77349.883959</td>\n",
       "      <td>-78408.573493</td>\n",
       "      <td>-174891.759801</td>\n",
       "      <td>221770.231981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   parton_t_lep_Px   parton_t_lep_Py   parton_t_lep_Pz   parton_t_lep_E  \\\n",
       "0      8945.401616      24636.989673    -217674.294110    278985.014576   \n",
       "1    -80118.597231      46734.359967    -196631.866458    280012.115606   \n",
       "2   -139068.409348      -5914.922283     -55932.889577    227050.154282   \n",
       "3    -11284.473842      33422.206289      45305.217967    182036.566037   \n",
       "4     37818.001459      -4590.763785       7451.532982    175849.295943   \n",
       "\n",
       "    parton_t_had_Px   parton_t_had_Py   parton_t_had_Pz   parton_t_had_E  \\\n",
       "0       8283.042475      72058.624950     -1.431059e+06     1.443269e+06   \n",
       "1      91834.412337     -30066.566498     -6.368368e+05     6.664149e+05   \n",
       "2     134884.134442      12118.102464      1.223401e+05     2.515827e+05   \n",
       "3     -20706.489425     -39816.182901      1.498502e+05     2.330612e+05   \n",
       "4     -80455.810381     -21964.950795     -6.285217e+04     2.021731e+05   \n",
       "\n",
       "    parton_W_had_Px   parton_W_had_Py      ...             b_lep_Pz  \\\n",
       "0      -5097.826232     113901.961619      ...         98667.859894   \n",
       "1      59056.754405      47526.569137      ...        -38662.132083   \n",
       "2     141515.876349      49417.990863      ...         92647.314813   \n",
       "3     -24395.980797     -60288.888919      ...        131924.418297   \n",
       "4    -116825.975467      -9179.879824      ...       -212533.902475   \n",
       "\n",
       "         b_lep_E       b_had_Px      b_had_Py       b_had_Pz        b_had_E  \\\n",
       "0  130343.023438  182480.734593 -86288.646457  126696.390732  238950.625000   \n",
       "1   92072.093750   24610.596015 -24885.721805   -1290.778056   35248.691406   \n",
       "2  104799.687500   12433.568687  39636.170358  167653.218337  172784.843750   \n",
       "3  270595.156250  -17549.408595  21488.410919   25310.706765   37834.363281   \n",
       "4  216230.812500   -4474.206790  59807.853057  -20406.806245   63570.820312   \n",
       "\n",
       "       W_lep_Px      W_lep_Py       W_lep_Pz        W_lep_E  \n",
       "0 -96273.537082  95614.983370  567624.355242  589988.274388  \n",
       "1   3843.260993 -36125.297978  104974.895963  137125.985111  \n",
       "2  64398.679896 -51801.203111  -50745.918019  125975.005508  \n",
       "3 -29762.306190 -98231.765180  481637.824359  498973.213324  \n",
       "4  77349.883959 -78408.573493 -174891.759801  221770.231981  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "in_datafile = \"in/ttj.csv\"\n",
    "df = pd.read_csv(in_datafile)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train dataframe of size:  722\n",
      "Created test dataframe of size:   390\n"
     ]
    }
   ],
   "source": [
    "fraction_train = 0.65 \n",
    "max_size = len(df)\n",
    "train_df = df[:int(max_size*fraction_train)]\n",
    "test_df  = df[int(max_size*fraction_train):max_size]\n",
    "print \"Created train dataframe of size: \", len(train_df)\n",
    "print \"Created test dataframe of size:  \", len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input X and Y vectors\n",
    "\n",
    "Set-up the input and output vectors. \n",
    "\n",
    "The output vector is going to be the jet indices:\n",
    "    ( \n",
    "    \n",
    "        is_fisrt_bjet_leptonic\n",
    "        is_second_bjet_hadronic,\n",
    "        is_in_W\n",
    "        is_in_W,\n",
    "        is_in_W,\n",
    "    )\n",
    "Then some spectator variables needed for the custom loss function that minimizes differences in four momenta: \n",
    "    (\n",
    "    \n",
    "        parton_top_had_p4,\n",
    "        parton_top_lep_p4,\n",
    "        parton_w_had_p4,\n",
    "        reco_w_lep_p4,\n",
    "        reco_bjet_1\n",
    "        reco_bjet_2\n",
    "        reco_jet_1\n",
    "        reco_jet_2\n",
    "        reco_jet_3     \n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(722, 20)\n",
      "(722, 36)\n",
      "(722, 39)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\"\"\"\n",
    "jet_1       \n",
    "jet_2       \n",
    "jet_3       \n",
    "bjet_1      \n",
    "bjet_2      \n",
    "t_lep_truth \n",
    "t_had_truth \n",
    "w_had_truth\n",
    "w_lep_truth \n",
    "\"\"\"\n",
    "all_variables = list(df.columns.values)\n",
    "reco_variables = all_variables[12:24]+all_variables[32:40]\n",
    "# parton_variables = all_variables[0:12]+all_variables[24:32]+all_variables[40:44]\n",
    "parton_variables = all_variables[0:12]+all_variables[40:44]\n",
    "\n",
    "jet_input_train   =train_df[reco_variables].values\n",
    "Y_train = truth_input_train = train_df[reco_variables+parton_variables].values\n",
    "jet_input_test   =test_df[reco_variables].values\n",
    "Y_test = truth_input_test = test_df[reco_variables+parton_variables].values\n",
    "\n",
    "# Add the dummy assignment vectors \n",
    "# A\n",
    "for i in xrange(3):\n",
    "    Y_train =  np.insert(Y_train, len(Y_train[0]),0, axis=1)\n",
    "    Y_test =  np.insert(Y_test, len(Y_test[0]),0, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "print jet_input_train.shape\n",
    "print truth_input_train.shape\n",
    "print Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT as r \n",
    "from keras import backend as K\n",
    "\n",
    "def transform_to_jet_assignment(y_pred):\n",
    "    \"\"\"\n",
    "        Convert a 3-vector that sums to unity into a vector of 3 predictions\n",
    "        where:\n",
    "            first element represents  if jet_1 is in the  hadronic W\n",
    "            second element represents if jet_2 is in the  hadronic W\n",
    "            third element represents  if bjet_1 is in the hadronic top\n",
    "            \n",
    "            The jet_3 is therefore in the hadronic_W when (2 - [0]-[1] ) == 1\n",
    "            The bjet_2 is therefore in the hadronic_W when (1 - [2] ) == 1\n",
    "    \"\"\"\n",
    "#     y_pred[:,K.argmax(y_pred[:,:2])]  = 1.0\n",
    "#     y_pred[:,K.argmin(y_pred[:,1:3])] = 1.0\n",
    "    y_pred[:,K.argmin(y_pred[:,:3])]  *= 0.0\n",
    "    return y_pred\n",
    "\n",
    "def mass_diff_loss(y_true,y_pred):\n",
    "    \"\"\"\n",
    "        user defined evaluation function, return a pair (metric_name, result)        \n",
    "        See the following links for details \n",
    "            https://github.com/keras-team/keras/issues/4781\n",
    "            https://stackoverflow.com/questions/45961428/make-a-custom-loss-function-in-keras\n",
    "        \n",
    "        \n",
    "        Intended to be used with 16 so-called spectator variables that correspond to\n",
    "        the truth level leptonic and hadronic top, truth level hadronic W, and reconstucted\n",
    "        leptonic W boson four momemtum\n",
    "        \n",
    "        A further 20 spectator variables are passed that correspond to the reconstruction level\n",
    "        jets, 3 light jets and 2 b-jets. \n",
    "        \n",
    "        The only part of y_pred that effects this loss function is the last 3 elements. These \n",
    "        correspond to jet assignment. \n",
    "    \"\"\"\n",
    "    # Note everything is done by tensor algebra - so this actually working things out for\n",
    "    # every event in a batch all in one go using a highly optimized tensorflow backend\n",
    "        \n",
    "    # Transform predictions into booleans that represent\n",
    "    # if a jet is a decay product of the hadronic top quark \n",
    "    assignment = y_pred[:,:3]#transform_to_jet_assignment(y_pred) \n",
    "#     assignment[:,K.argmax(assignment[:,:2])]\n",
    "#     t = y_pred[:,K.argmax(assignment[:,:2])]\n",
    "#     assignment[:,0].assign_slice( 1.0)\n",
    "#     assignment[:,:].assign(K.zeros( 3 ))\n",
    "#     assignment[:,0] = 0.0\n",
    "\n",
    "    # Get the four vectors for each of the needed physics objects\n",
    "    # we're in a basis such that each four vector = (px,py,pz,E)\n",
    "    jet_1        = y_pred[:,0:4]/1e3\n",
    "    jet_2        = y_pred[:,4:8]/1e3\n",
    "    jet_3        = y_pred[:,8:12]/1e3\n",
    "    bjet_1       = y_pred[:,12:16]/1e3\n",
    "    bjet_2       = y_pred[:,16:20]/1e3\n",
    "    t_lep_truth  = y_pred[:,20:24]/1e3\n",
    "    t_had_truth  = y_pred[:,24:28]/1e3\n",
    "    w_had_truth  = y_pred[:,28:32]/1e3\n",
    "    w_lep_truth  = y_pred[:,32:36]/1e3\n",
    "\n",
    "    # calculated the masses for all of the predictions and truth level objects\n",
    "    top_hadronic_px  = assignment[:,0]*jet_1[:,0] + assignment[:,1]*jet_2[:,0] + (2-assignment[:,1])*jet_3[:,0] + assignment[:,2]*bjet_1[:,0]+ (1-assignment[:,2])*bjet_2[:,0]\n",
    "    top_hadronic_py  = assignment[:,0]*jet_1[:,1] + assignment[:,1]*jet_2[:,1] + (2-assignment[:,1])*jet_3[:,1] + assignment[:,2]*bjet_1[:,1]+ (1-assignment[:,2])*bjet_2[:,1]\n",
    "    top_hadronic_pz  = assignment[:,0]*jet_1[:,2] + assignment[:,1]*jet_2[:,2] + (2-assignment[:,1])*jet_3[:,2] + assignment[:,2]*bjet_1[:,2]+ (1-assignment[:,2])*bjet_2[:,2]\n",
    "    top_hadronic_e   = assignment[:,0]*jet_1[:,3] + assignment[:,1]*jet_2[:,3] + (2-assignment[:,1])*jet_3[:,3] + assignment[:,2]*bjet_1[:,3]+ (1-assignment[:,2])*bjet_2[:,3]    \n",
    "    top_hadronic_m   = K.sqrt(-K.square(top_hadronic_e)+K.square(top_hadronic_px)+K.square(top_hadronic_py)+K.square(top_hadronic_py))\n",
    "\n",
    "    w_hadronic_px  = assignment[:,0]*jet_1[:,0] + assignment[:,1]*jet_2[:,0]  + (2-assignment[:,1])*jet_3[:,0]\n",
    "    w_hadronic_py  = assignment[:,0]*jet_1[:,1] + assignment[:,1]*jet_2[:,1]  + (2-assignment[:,1])*jet_3[:,1]\n",
    "    w_hadronic_pz  = assignment[:,0]*jet_1[:,2] + assignment[:,1]*jet_2[:,2]  + (2-assignment[:,1])*jet_3[:,2]\n",
    "    w_hadronic_e   = assignment[:,0]*jet_1[:,3] + assignment[:,1]*jet_2[:,3]  + (2-assignment[:,1])*jet_3[:,3]\n",
    "    w_hadronic_m   = K.sqrt(-K.square(w_hadronic_e) + K.square(w_hadronic_px)+K.square(w_hadronic_py)+K.square(w_hadronic_pz))\n",
    "    \n",
    "    t_lep_truth_m   = K.sqrt(-K.square(t_lep_truth[:,3]) + K.square(t_lep_truth[:,0]) + K.square(t_lep_truth[:,1]) + K.square(t_lep_truth[:,2]))\n",
    "    t_had_truth_m   = K.sqrt(-K.square(t_had_truth[:,3]) + K.square(t_had_truth[:,0]) + K.square(t_had_truth[:,1]) + K.square(t_had_truth[:,2]))\n",
    "    w_had_truth_m   = K.sqrt(-K.square(w_had_truth[:,3]) + K.square(w_had_truth[:,0]) + K.square(w_had_truth[:,1]) + K.square(w_had_truth[:,2]))\n",
    "    w_lep_truth_m   = K.sqrt(-K.square(w_lep_truth[:,3]) + K.square(w_lep_truth[:,0]) + K.square(w_lep_truth[:,1]) + K.square(w_lep_truth[:,2]))\n",
    "\n",
    "    top_lep_pz = w_lep_truth[:,0] + (1-assignment[:,2])*bjet_1[:,0]+ (assignment[:,2])*bjet_2[:,0]\n",
    "    top_lep_py = w_lep_truth[:,1] + (1-assignment[:,2])*bjet_1[:,1]+ (assignment[:,2])*bjet_2[:,1]\n",
    "    top_lep_px = w_lep_truth[:,2] + (1-assignment[:,2])*bjet_1[:,2]+ (assignment[:,2])*bjet_2[:,2]\n",
    "    top_lep_e  = w_lep_truth[:,3] + (1-assignment[:,2])*bjet_1[:,3]+ (assignment[:,2])*bjet_2[:,3]\n",
    "    top_lep_m  = -K.square(top_lep_e) + (K.square(top_lep_px)+K.square(top_lep_py)+K.square(top_lep_pz))\n",
    "    # Return the loss as the differences in mass for each of the reconstructed objects \n",
    "    return K.square(top_lep_m-t_lep_truth_m) + K.square(top_hadronic_m-t_had_truth_m)+K.square(w_hadronic_m-w_had_truth_m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "RecoJetInput (InputLayer)        (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "JetAssignmentLayer (Dense)       (None, 32)            672         RecoJetInput[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "TruthLevelInput (InputLayer)     (None, 36)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "JetAssignment2ndLayer (Dense)    (None, 3)             99          JetAssignmentLayer[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "Combination (Concatenate)        (None, 39)            0           TruthLevelInput[0][0]            \n",
      "                                                                   JetAssignment2ndLayer[0][0]      \n",
      "====================================================================================================\n",
      "Total params: 771\n",
      "Trainable params: 771\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense,Concatenate,concatenate\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# Construct the jet assignment part of the network, a simple MLP\n",
    "jet_assignment_input  = Input(shape=(20,), dtype='float32', name='RecoJetInput')\n",
    "jet_assignment_hidden = Dense(32, activation='relu', name='JetAssignmentLayer')(jet_assignment_input)\n",
    "jet_assignment_output = Dense(3,  activation='softmax', name='JetAssignment2ndLayer')(jet_assignment_hidden)\n",
    "\n",
    "# Potenttially might want to add additional W mass reconstruction part of the network here??\n",
    "# auxiliary_output = Dense(3, activation='sigmoid', name='aux_output')(jet_assignment_input)\n",
    "\n",
    "# Merge in truth level information required for the \n",
    "auxiliary_input = Input(shape=(36,), name='TruthLevelInput')\n",
    "total_model = concatenate([ auxiliary_input,jet_assignment_output], name='Combination')\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "# output = Dense(3, activation='sigmoid', name='Output')(x)\n",
    "\n",
    "model = Model(inputs=[jet_assignment_input,auxiliary_input], outputs=[total_model])\n",
    "model.compile(optimizer='rmsprop', loss=mass_diff_loss)\n",
    "model.summary()\n",
    "plot_model(model, to_file='model.png',show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 613 samples, validate on 109 samples\n",
      "Epoch 1/15\n",
      "613/613 [==============================] - 7s - loss: 808941145562171544403157140373504.0000 - val_loss: 7146739755615783733801584164864.0000\n",
      "Epoch 2/15\n",
      "613/613 [==============================] - 0s - loss: 808941079479978712228308507951104.0000 - val_loss: 7146739755615783733801584164864.0000\n",
      "Epoch 3/15\n",
      "613/613 [==============================] - 0s - loss: 808941086130180118826576907337728.0000 - val_loss: 7146739755615783733801584164864.0000\n",
      "Epoch 4/15\n",
      "613/613 [==============================] - 0s - loss: 808941087965139144908586321182720.0000 - val_loss: 7146739755615783733801584164864.0000\n",
      "Epoch 5/15\n",
      "613/613 [==============================] - 0s - loss: 808941056321713111782195984334848.0000 - val_loss: 7146739755615783733801584164864.0000\n",
      "Epoch 6/15\n",
      "613/613 [==============================] - 0s - loss: 808941061957942248817706150133760.0000 - val_loss: 7146739755615783733801584164864.0000\n",
      "Epoch 7/15\n",
      "613/613 [==============================] - 0s - loss: 808941083777778968722720805617664.0000 - val_loss: 7146739755615783733801584164864.0000\n",
      "Epoch 8/15\n",
      "613/613 [==============================] - 0s - loss: 808941033788301999680191274680320.0000 - val_loss: 7146739755615783733801584164864.0000\n",
      "Epoch 9/15\n",
      "613/613 [==============================] - 0s - loss: 808941091621498840178428628434944.0000 - val_loss: 7146739755615783733801584164864.0000\n",
      "Epoch 10/15\n",
      "613/613 [==============================] - 0s - loss: 808941056375296147515115728535552.0000 - val_loss: 7146739755615783733801584164864.0000\n",
      "Epoch 11/15\n",
      "613/613 [==============================] - 0s - loss: 808941036691917947555530508599296.0000 - val_loss: 7146739755615783733801584164864.0000\n",
      "Epoch 12/15\n",
      "613/613 [==============================] - 0s - loss: 808941058315888435922589827727360.0000 - val_loss: 7146739755615783733801584164864.0000\n",
      "Epoch 13/15\n",
      "613/613 [==============================] - 0s - loss: 808941077481208275316116000079872.0000 - val_loss: 7146739755615783733801584164864.0000\n",
      "Epoch 14/15\n",
      "613/613 [==============================] - 0s - loss: 808941084636155834327500488441856.0000 - val_loss: 7146739755615783733801584164864.0000\n",
      "Epoch 15/15\n",
      "613/613 [==============================] - 0s - loss: 808941068129289525922942878220288.0000 - val_loss: 7146739755615783733801584164864.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x163cbdf10>"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( [jet_input_train,truth_input_train],\n",
    "          Y_train, \n",
    "          validation_split = 0.15,\n",
    "#           batch_size=50,\n",
    "          epochs = 15\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict([jet_input_test,truth_input_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[3,-3:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
